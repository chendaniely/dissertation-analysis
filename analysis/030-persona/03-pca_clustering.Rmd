---
title: "Clustering"
output: 
  html_document: 
    toc: yes
    df_print: kable
    fig_width: 8
    fig_height: 5
editor_options: 
  chunk_output_type: console
params:
  survey_data: "survey_likert"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
options(width = 100)

library(readr)
library(here)
library(tibble)
library(dplyr)
library(cluster)
library(purrr)
library(tidyr)
library(factoextra)
library(fs)
library(glue)
library(ggdendro)
library(ggplot2)

source(here::here("./R/gg_plot_dendro.R"))

# params <- list(); params$survey_data <- "survey_likert"
stopifnot(
  params$survey_data %in% c("survey_likert", "survey_only", "likert_only")
)

fs::dir_create(here(glue::glue("./output/persona/{params$survey_data}")))

survey_data_pth <- switch(
  params$survey_data,
  "survey_likert" = here::here("./data/final/persona/01-participant_numeric-wide_survey_likert.csv"),
  "survey_only" = here::here("./data/final/persona/01-participant_numeric-wide_survey_only.csv"),
  "likert_only" = here::here("./data/final/persona/01-participant_numeric-wide_likert_only.csv")
)


# this file comes from validation 010-prep_survey_questions.R
wide <- readr::read_csv(survey_data_pth)

#stopifnot(nrow(wide) == 59)

persona <- readr::read_tsv(here("./data/final/01-surveys/01-self_assessment_persona_with_questions.tsv"))

# make sure the row names are the same as the IDs before dropping
wide <- tibble::column_to_rownames(wide, var = "id_person")
stopifnot(all(rownames(wide) == wide$id))

rownames(wide)

numeric_data <- wide
```

```{r}

# should only have the text responses to convert to factors
# stopifnot(all(lapply(wide, class) == "character"))
# q3.1_unique <- length(wide$Q3.1 %>% unique())
# numeric_data <- purrr::map_df(wide, ~as.numeric(as.factor(.)))
# stopifnot(length(unique(numeric_data$Q3.1)) == q3.1_unique)
# 
# rownames(numeric_data) <- rownames(wide)
```

# The data

```{r}
tail(numeric_data)
```

The data are the numeric (factor) survey responses.
They are not `scale`d, but the units are arbitrary.
Using `scale` would scale/standardize the results.
But these are factor responses, not an actual measurement.
**This needs to be consulted.**

Scaling the data would look like this:

```{r}
numeric_data_scaled <- scale(numeric_data)
```


```{r}
numeric_data_scaled[1:5, 1:6]
```



# PCA

```{r}
pca_persona_scaled <- prcomp(numeric_data_scaled)
summary(pca_persona_scaled)
```

```{r}
saveRDS(pca_persona_scaled, file = here(glue::glue("./output/persona/{params$survey_data}/pca_results.RDS")))
```

```{r}
pca_table_mat <- t(summary(pca_persona_scaled)$importance)
components <- rownames(pca_table_mat)

pca_results_df <- pca_table_mat %>%
  tibble::as_tibble() %>%
  dplyr::mutate(component = components,
                compont_num = stringr::str_replace(component, "PC", "") %>%
                  as.numeric())
pca_results_df
```

```{r}
ggplot(pca_results_df,
       aes(x = as.factor(compont_num),
           y = `Cumulative Proportion`,
           group = 1)) +
  geom_point() +
  geom_line() +
  ylim(0, 1) +
  geom_hline(yintercept = 0.5, linetype = 'dashed', col = 'blue') +
  geom_hline(yintercept = 0.9, linetype = 'longdash', col = 'red') +
  annotate("text", x = "15", y = 0.5, label = "50%", vjust = 0) +
  annotate("text", x = "15", y = 0.9, label = "90%", vjust = 0) +
  labs(title = "Principal Component Results",
       x = "Principal Component") +
  theme_minimal() +
  theme(text = element_text(size=20))
```

```{r}
ggsave(here(glue::glue("./output/persona/{params$survey_data}/pca_cum_prop.png")))
```


Half of the components account for >90% of the variance.
Will need to confirm these results with factor analysis,
but this makes sense since I tried to ask the same questions in 2 ways.


# Hierarchical Clustering

https://uc-r.github.io/hc_clustering

```{r}
dist <- dist(numeric_data_scaled, method = "euclidean")
```

## Finding the clustering method

### Complete

Computes pairwise similarities, and the "most" (i.e., maximum) similar ones are grouped together

```{r}
# Hierarchical Clustering with hclust
hc_complete <- hclust(dist, method = "complete")
# Plot the result
plot(hc_complete, cex = 0.6, hang = -1)
```

### Ward's

Minimizes the total **within cluster** variance.

From the docs:

> Two different algorithms are found in the literature for Ward clustering. The one used by option "ward.D" (equivalent to the only Ward option "ward" in R versions <= 3.0.3) does not implement Ward's (1963) clustering criterion, whereas option "ward.D2" implements that criterion (Murtagh and Legendre 2014). With the latter, the dissimilarities are squared before cluster updating. Note that agnes(*, method="ward") corresponds to hclust(*, "ward.D2").

```{r}
hc_ward <- hclust(dist, method = "ward.D2")
# Plot the result
plot(hc_ward, cex = 0.6, hang = -1)
```

### Comparing dendograms

Calculate agglomerative coefficient (closer to 1 mean stronger clustering structure)

```{r}
m <- c("average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

purrr::map_dbl(m, ~ cluster::agnes(numeric_data_scaled, method = .)$ac)
```

Ward's gives us the best clustering structure

```{r}
hc_agnes_wards <- agnes(numeric_data_scaled, method = "ward")
cluster::pltree(hc_agnes_wards, cex = 0.6, hang = -1, main = "Dendrogram of agnes")
```

## Cutting the tree to create clusters

```{r}
hc_ward
```

```{r}
sub_grp2 <- cutree(hc_ward, k = 2)
sub_grp3 <- cutree(hc_ward, k = 3)
sub_grp4 <- cutree(hc_ward, k = 4)
sub_grp5 <- cutree(hc_ward, k = 5)
sub_grp6 <- cutree(hc_ward, k = 6)
```

```{r}
numeric_data <- numeric_data %>%
  dplyr::mutate(
    group2 = sub_grp2,
    group3 = sub_grp3,
    group4 = sub_grp4,
    group5 = sub_grp5,
    group6 = sub_grp6
  )
rownames(numeric_data) <- rownames(wide)
```


```{r}
plot_all_dendros <- function(hc_dat, k, ...) {
  png(here::here(glue::glue("./output/persona/{params$survey_data}/dendogram_{k}.png")),
      width = 13, height = 8, units = "in", res = 72)
  plot(hc_ward, cex = 0.6)
  rect.hclust(hc_ward, k = k, border = 2:3)
  dev.off()
  
  g <- gg_plot_dendro(hc_ward, ...)
  print(g)
  
  ggsave(here::here(glue::glue("./output/persona/{params$survey_data}/dendogram_{k}_gg.png")),
         plot = g,
         width = 13, height = 8, units = "in", dpi = 72)
}
```

```{r}
plot_all_dendros(hc_ward, k = 2, group2)
```

```{r}
plot_all_dendros(hc_ward, k = 3, group3)
```

```{r}
plot_all_dendros(hc_ward, k = 4, group4)
```

```{r}
plot_all_dendros(hc_ward, k = 5, group5)
```

### Finding optimal clusters

```{r}
# https://www.r-bloggers.com/2017/12/how-to-perform-hierarchical-clustering-using-r/
# https://www.r-bloggers.com/2019/01/10-tips-for-choosing-the-optimal-number-of-clusters/
```



#### Elbow method

https://uc-r.github.io/kmeans_clustering#elbow

```{r}
png(here(glue::glue("./output/persona/{params$survey_data}/elbow_plot.png")))
factoextra::fviz_nbclust(numeric_data_scaled, FUN = factoextra::hcut, method = "wss")
dev.off()
```

#### Gap statistic

```{r}
png(here(glue::glue("./output/persona/{params$survey_data}/gap_statistic.png")))
gap_stat <- clusGap(numeric_data_scaled, FUN = kmeans, nstart = 30, K.max = 24, B = 50)
fviz_gap_stat(gap_stat) + theme_minimal() + ggtitle("fviz_gap_stat: Gap Statistic")
dev.off()
```


Will need to look at the results to see if they create meaningful personas

# Write out group data

```{r}
gps <- 2:5

fs::dir_create(here(glue::glue("./data/final/persona/{params$survey_data}/")))
persona_df_pths <- here(glue::glue("./data/final/persona/{params$survey_data}/persona_group_{gps}.tsv"))
cols <- glue::glue("group{gps}")

persona_groups <- purrr::map(
  cols,
  function(x) {
    group_data <- numeric_data %>%
      tibble::rownames_to_column(var = "id_person") %>%
      dplyr::select(id_person, {{ x }})
    
    stopifnot(nrow(numeric_data_scaled) == nrow(group_data))
    stopifnot(all(unique(group_data$id_person) %in% unique(persona$id_person)))
    
    dat <- persona %>%
      dplyr::mutate(id_person = as.character(id_person)) %>%
      dplyr::left_join(group_data, by = c("id_person" = "id_person"))
    
    return(dat)
  }
)

purrr::walk2(
  persona_groups,
  persona_df_pths,
  function(dat, pth){readr::write_tsv(dat, pth)}
)
```

# K-Means

https://uc-r.github.io/kmeans_clustering

```{r}
numeric_data_scaled
```

```{r}
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
```

```{r}
dist <- factoextra::get_dist(numeric_data_scaled, method = "euclidean")
```

```{r}
fviz_dist(dist, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k2 <- kmeans(numeric_data_scaled, centers = 2, nstart = 25)
k3 <- kmeans(numeric_data_scaled, centers = 3, nstart = 25)
k4 <- kmeans(numeric_data_scaled, centers = 4, nstart = 25)
k5 <- kmeans(numeric_data_scaled, centers = 5, nstart = 25)

# plots to compare
pk2 <- fviz_cluster(k2, geom = "point", data = numeric_data_scaled) + ggtitle("k = 2")
pk3 <- fviz_cluster(k3, geom = "point", data = numeric_data_scaled) + ggtitle("k = 3")
pk4 <- fviz_cluster(k4, geom = "point", data = numeric_data_scaled) + ggtitle("k = 4")
pk5 <- fviz_cluster(k5, geom = "point", data = numeric_data_scaled) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(pk2, pk3, pk4, pk5, nrow = 2)
```
