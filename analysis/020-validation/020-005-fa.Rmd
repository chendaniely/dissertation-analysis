---
title: "PCA and Factor Analysis"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(readr)
library(tibble)
library(psych)
library(here)
library(dplyr)
library(GPArotation)
library(progress)
library(flextable)
library(xtable)
library(corrplot)
library(nFactors)

knitr::opts_chunk$set(echo = TRUE)

fs::dir_create(here::here("../dissertation-edt/figs/010-validation/"))
```

```{r}
# from: https://www.anthonyschmidt.co/post/2020-09-27-efa-tables-in-r/
fa_table <- function(x, cut) {
  #get sorted loadings
  loadings <- fa.sort(x)$loadings %>% round(3)
  #supress loadings
  loadings[loadings < cut] <- ""
  #get additional info
  add_info <- cbind(x$communalities, 
                    x$uniquenesses,
                    x$complexity) %>%
    # make it a data frame
    as.data.frame() %>%
    # column names
    rename("Communality" = V1,
           "Uniqueness" = V2,
           "Complexity" = V3) %>%
    #get the item names from the vector
    rownames_to_column("item")
  #build table
  loadings %>%
    unclass() %>%
    as.data.frame() %>%
    rownames_to_column("item") %>%
    left_join(add_info) %>%
    mutate(across(where(is.numeric), round, 3))
}

flex <- function(data, title=NULL) {
  # this grabs the data and converts it to a flextbale
  flextable(data) %>%
    # this makes the table fill the page width
    set_table_properties(layout = "autofit", width = 1) %>%
    # font size
    fontsize(size=10, part="all") %>%
      #this adds a ttitlecreates an automatic table number
        set_caption(title, 
                    autonum = officer::run_autonum(seq_id = "tab", 
                                                   pre_label = "Table ", 
                                                   post_label = "\n", 
                                                   bkm = "anytable")) %>%
    # font type
    flextable::font(fontname="Times New Roman", part="all")
}
```


```{r}
numeric <- readr::read_csv(here::here("./data/final/persona/01-participant_numeric-wide_survey_likert.csv"))
questions <- readr::read_tsv(here("./data/final/01-surveys/01-self_assessment_persona_questions_meta.tsv"))

numeric <- tibble::column_to_rownames(numeric, var = "id_person")
scaled <- scale(numeric)
```

# Data correlation

Taken from Jen at biostat office hours

```{r}
#############################################################
# Examine the data correlation to determine if FA is appropriate
#############################################################
# Create the correlation matrix from the simulated data 
data_corr <- cor(scaled, use="complete.obs")
sim_data_corr <- round(data_corr,2)
sim_data_corr

# Look at the p-values
sim_data_corr_p <- corr.test(scaled, use = "complete.obs")$p
sim_data_corr_p

sig_p <- vector(mode='character', length=nrow(sim_data_corr_p)*ncol(sim_data_corr_p))
index <- 1

for(i in 1:nrow(sim_data_corr_p)){
  for(j in 1:ncol(sim_data_corr_p)){
    if(i == j){
      sig_p[index] = 'Identity'
    }else if(sim_data_corr_p[i,j] <= 0.05 & abs(sim_data_corr[i,j]) >= 0.5){
      sig_p[index] = 'Significant'
    }else{
      sig_p[index] = 'Not Significant'
    }
    index <-index + 1
  }
}

table(sig_p)

dat_corr <- sim_data_corr %>%
  tibble::as_tibble(rownames = "row") %>%
  tidyr::pivot_longer(-row) %>%
  dplyr::rename(corr = value)

dat_p <- sim_data_corr_p %>%
  tibble::as_tibble(rownames = "row") %>%
  tidyr::pivot_longer(-row) %>%
  dplyr::rename(p = value)

dat_corr_p_sig <- dplyr::inner_join(dat_corr,
                                    dat_p,
                                    by = c("row", "name")) %>%
  dplyr::mutate(sig = dplyr::case_when(
    corr == 1 & p == 0 ~ "identity",
    abs(corr) >= 0.5 & p < 0.05 ~ "significant",
    TRUE ~ "not significant"
  ))

dat_corr_p_sig %>%
  dplyr::count(sig) # should get same results as table(sig_p)


```

```{r}
get_corrplor <- function(dat_corr, dat_corr_p, colors) {
  corrplot(dat_corr,
           method="color",
           col=colors(200),  
           type="full",
           order="hclust", 
           hclust.method = "ward.D2",
           addCoef.col = "black", # Add coefficient of correlation
           
           tl.col="black",
           tl.srt=45, #Text label color and rotation
           
           number.cex = 0.80, # text size of corr in corr matrix
           
           # Combine with significance
           p.mat = sim_data_corr_p,
           sig.level = 0.05,
           insig = "blank", 
           
           # hide correlation coefficient on the principal diagonal
           diag=TRUE 
  )
}
```

```{r}
# Visualize the correlation matrix
# from http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

get_corrplor(data_corr, sim_data_corr_p, col)
```

```{r}
png(here::here("./output/persona/efa_item_correlations.png"), width = 800, height = 800)
get_corrplor(data_corr, sim_data_corr_p, col)
dev.off()


png(here::here("../dissertation-edt/figs/010-validation/efa_item_correlations.png"), width = 800, height = 800)
get_corrplor(data_corr, sim_data_corr_p, col)
dev.off()
```


"bad" questions

```{r}
# these counts are based off the identity/sig/not-sig counts,
# not off corr plot non-blank values
dat_corr_p_sig <- dat_corr_p_sig %>%
  dplyr::filter(sig  == "significant") %>%
  dplyr::count(row, sort = TRUE) %>%
  dplyr::mutate(
    prop = n / ncol(scaled) # get proportion significant cols from total cols
  )

good_questions <- dat_corr_p_sig %>%
  dplyr::filter(prop > 0.2) %>%
  dplyr::pull(row)

print(length(good_questions))
good_questions
```

```{r}
print(length(good_questions))
```


```{r}
scaled_good <- numeric %>%
  dplyr::select(tidyselect::all_of(good_questions)) %>%
  scale()
```



# EFA

Taken from: https://www.statmethods.net/advstats/factor.html

```{r}
get_scree_values <- function(scaled_dat) {
  ev <- eigen(cor(scaled_dat)) # get eigenvalues
  ap <- parallel(subject = nrow(scaled_dat),
                 var=ncol(scaled_dat),
                 rep=100,
                 cent=.05)
  nS <- nFactors::nScree(x=ev$values,
                         aparallel=ap$eigen$qevpea)
  return(nS)
}
```


```{r}
# Determine Number of Factors to Extract

nS <- get_scree_values(scaled)

if (interactive()) {
  plotnScree(nS)
} else {
  png(here::here("./output/persona/efa_eigen_scree.png"))
  plotnScree(nS)
  dev.off()
  
  fs::dir_create(here::here("../dissertation-edt/figs/010-validation/"))
  png(here::here("../dissertation-edt/figs/010-validation/efa_eigen_scree.png"))
  plotnScree(nS)
  dev.off()
}

```

```{r}
# scree plot for just the good variables

ns_good <- get_scree_values(scaled_good)

if (interactive()) {
  plotnScree(ns_good)
} else {
  png(here::here("./output/persona/efa_eigen_scree_good.png"))
  plotnScree(ns_good)
  dev.off()
  
  fs::dir_create(here::here("../dissertation-edt/figs/010-validation/"))
  png(here::here("../dissertation-edt/figs/010-validation/efa_eigen_scree_good.png"))
  plotnScree(ns_good)
  dev.off()
}
```



## Loadings

```{r}
my_efa <- function(scaled_dat, nfactors, rotation, factor_method) {
  #print("*********************************************************************")
  #print(glue::glue("nfactors: {nfactors}\nroation: {rotation}\nfactor_method: {factor_method}"))
  pb$tick()
  
  efa_res <- psych::fa(scaled_dat, nfactors = nfactors, scores = "tenBerge", fm = factor_method)
  
  res <- tibble::tribble(~nfactors, ~rotation, ~fm,           ~tli,        ~rmsea,             ~bic,
                         nfactors,  rotation,  factor_method, efa_res$TLI, efa_res$RMSEA[[1]], efa_res$BIC)
  
  return(res)
}
```

```{r}
nfactors_try <- 2:4
rotation_try <- c("none", "varimax", "quartimax", "bentlerT", "equamax", "varimin", "geominT", "bifactor", # orthogonal
                  "Promax", "promax", "oblimin", "simplimax", "bentlerQ", "geominQ", "biquartimin", "cluster" # oblique
                  )
fm_try <- c("minres", "uls", "ols", "wls", "gls", "pa", "ml", "minchi", "minrank", "old.min", "alpha")
param_grid <- expand.grid(nfactors_try = nfactors_try,
                          rotation_try = rotation_try,
                          fm_try = fm_try,
                          stringsAsFactors = FALSE
                          )
```

```{r}
l_params <- list(nfactors = param_grid$nfactors_try,
                 rotation = param_grid$rotation_try,
                 factor_method = param_grid$fm_try
                 )

pb <- progress_bar$new(total = nrow(param_grid))

safe_my_efa <- purrr::safely(my_efa)

all_param_res <- purrr::pmap(l_params,
                             function(nfactors, rotation, factor_method) {
                               safe_my_efa(scaled, nfactors, rotation, factor_method)
                             }
)
```

```{r}
t <- all_param_res %>%
  purrr::transpose() %>%
  purrr::simplify_all()

all_res_df <- t$result %>%
  dplyr::bind_rows()
```

```{r}
good_res_combos <- all_res_df %>%
  dplyr::filter(tli >= 0.9, rmsea < 0.08)
```

```{r}
good_res_combos %>%
  dplyr::count(nfactors)
```

```{r}
fa_cutoff <- 0.50
```

#### Good vars

```{r}
all_param_res_good <- purrr::pmap(l_params,
                                  function(nfactors, rotation, factor_method) {
                                    safe_my_efa(scaled_good, nfactors, rotation, factor_method)
                                  }
)

t_good <- all_param_res_good %>%
  purrr::transpose() %>%
  purrr::simplify_all()

all_res_good_df <- t_good$result %>%
  dplyr::bind_rows()

good_res_combos <- all_res_good_df %>%
  dplyr::filter(tli >= 0.9, rmsea < 0.08)

good_res_combos %>%
  dplyr::count(nfactors)
```

```{r}
fac3_mods_good <- all_res_good_df %>%
  dplyr::filter(rotation == "varimax", nfactors == 3) %>%
  arrange(bic)
fac3_mods_good
```

```{r}
fac3_mods_good %>%
  xtable::xtable()
```


```{r}
good_combos <- all_res_good_df %>%
  dplyr::filter(tli >= 0.9,
                rmsea < 0.08,
                rotation == "varimax"
                ) %>%
  dplyr::arrange(bic)

good_combos
```

```{r}
xtable::xtable(good_combos)
```




### Item distributions

```{r}
apply(scaled, 2, hist)
```

https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test: 

The null-hypothesis of this test is that the population is normally distributed. Thus, if the p value is less than the chosen alpha level, then the null hypothesis is rejected and there is evidence that the data tested are not normally distributed

```{r}
apply(scaled, 2, shapiro.test)
```

```{r}
library(MVN)
res <- mvn(scaled, mvnTest = "mardia", univariatePlot = "qq")
res
```

```{r}
apply(scaled, 2, function(x){
  qqnorm(x, pch = 1, frame = FALSE)
  qqline(x, col = "steelblue", lwd = 2)
})
```

### 2 Loadings


```{r}
f2 <- fa(scaled, 2, rotate="varimax", scores="tenBerge", fm = "minchi")
print(f2)
factor.stats(scaled, f2, n.obs = nrow(scaled))
```

```{r}
f2$loadings
```

```{r}
fa_table(f2, fa_cutoff)
```

```{r}
fa_table(f2, fa_cutoff) %>%
  flex("A Pretty Factor Analysis Table")
```

```{r}
xtable::xtable(fa_table(f2, fa_cutoff))
```



### 3 Loadings


```{r}
f3 <- fa(scaled, 3, rotate="varimax", scores="tenBerge", fm = "minchi")
print(f3)
factor.stats(scaled, f3, n.obs = nrow(scaled))
```

```{r}
f3$loadings
```

```{r}
f3 <- fa(scaled, 3, rotate="promax", scores="tenBerge", fm = "minchi")
print(f3)
factor.stats(scaled, f3, n.obs = nrow(scaled))
```

```{r}
f3$loadings
```

```{r}
xtable::xtable(fa_table(f3, fa_cutoff))
```

#### Good

```{r}
f3_good <- fa(scaled_good, 3, rotate="varimax", scores="tenBerge", fm = "pa")
print(f3_good)
factor.stats(scaled_good, f3_good, n.obs = nrow(scaled_good))
```

```{r}
psych::fa.diagram(f3_good)
```

```{r}
fa_table(f3_good, fa_cutoff)
```


```{r}
xtable::xtable(fa_table(f3_good, fa_cutoff))
```


### 4 Loadings

```{r}
f4 <- fa(scaled, 4, rotate="varimax", scores="tenBerge", fm = "minchi")
print(f4)
factor.stats(scaled, f4, n.obs = nrow(scaled))
```

```{r}
f4$loadings
```

```{r}
xtable::xtable(fa_table(f4, fa_cutoff))
```

#### Good

```{r}
f4_good <- fa(scaled_good, 4, rotate="varimax", scores="tenBerge", fm = "ml")
print(f4_good)
factor.stats(scaled_good, f4_good, n.obs = nrow(scaled))
```

```{r}
psych::fa.diagram(f4_good)
```

```{r}
fa_table(f4_good, fa_cutoff)
```


```{r}
xtable::xtable(fa_table(f4_good, fa_cutoff))
```


### 5 Loadings

```{r}
f5 <- fa(scaled, 5, rotate="varimax", scores="tenBerge", fm = "ml")
print(f5)
factor.stats(scaled, f5, n.obs = nrow(scaled))
```

```{r}
xtable::xtable(fa_table(f5, fa_cutoff))
```



### 2 Loadings

```{r}
efa2 <- factanal(scaled, factors = 2, rotation = "varimax")
print(efa2, digits=2, cutoff=.3, sort=TRUE)
```

```{r}
efa2 <- factanal(scaled, factors = 2, rotation = "promax")
print(efa2, digits=2, cutoff=.3, sort=TRUE)

saveRDS(efa2, here("./data/final/persona/efa2-promax.RDS"))
```

```{r}
f2 <- fa(scaled, 2, scores="tenBerge")
print(f2)
factor.stats(scaled, f2, n.obs = nrow(scaled))

f2o <- fa(scaled, 2, fm="pa", rotate="Promax")
factor.stats(scaled, f2o, n.obs = nrow(scaled))
```


```{r}
load <- efa2$loadings[, 1:2]
plot(load,type="n") # set up plot
text(load,labels=names(numeric),cex=.7) # add variable names 
```

### 3 Loadings

```{r}
efa3 <- factanal(scaled, factors = 3, rotation = "varimax")
print(efa3, digits=2, cutoff=.3, sort=TRUE)
```

```{r}
efa3 <- factanal(scaled, factors = 3, rotation = "promax")
print(efa3, digits=2, cutoff=.3, sort=TRUE)
```

```{r}
saveRDS(efa3, here("./data/final/persona/efa3-promax.RDS"))
```

```{r}
psych::fac(scaled, nfactors = 3, rotate = "promax")
```

```{r}
psych::fac(scaled, nfactors = 2, rotate = "promax")
```




```{r}
f3 <- fa(scaled, 3)
factor.stats(scaled, f3, n.obs = nrow(scaled))

f3o <- fa(scaled, 3, fm="pa", rotate="Promax")
factor.stats(scaled, f3o, n.obs = nrow(scaled))
```


```{r}
load <- efa3$loadings[, 1:2]
plot(load,type="n") # set up plot
text(load,labels=names(numeric),cex=.7) # add variable names 
```

### 4 Loadings

```{r}
efa4 <- factanal(scaled, factors = 4, rotation = "varimax")
print(efa4, digits=2, cutoff=.3, sort=TRUE)
```

```{r}
efa4 <- factanal(scaled, factors = 4, rotation = "promax")
print(efa4, digits=2, cutoff=.3, sort=TRUE)
```

```{r}
load <- efa3$loadings[, 1:2]
plot(load,type="n") # set up plot
text(load,labels=names(numeric),cex=.7) # add variable names 
```

Looking at the CFA results and interprebility, I'm using 3 factors.
Results using promax rotation.

- Programming:
  - Q3.3: How familiar are you with interactive programming languages like Python or R?
- Stats:
  - Q6.2: If you were given a dateset containing an individual's smoking status (binary variable) and whether or not they have hypertension (binary variable), would you know how to conduct a statistical analysis to see if smoking has an increased relative risk or odds of hypertension? Any type of model will suffice.
- Data:
  - Q4.4: Do you know what "long" and "wide" data are?

```{r}
scaled_subq <- scaled[, c("Q3.3", "Q6.2", "Q4.4")]
```

```{r}
scaled_subq
```

```{r}
dist <- dist(scaled_subq, method = "euclidean")
hc_ward <- hclust(dist, method = "ward.D2")
# Plot the result
plot(hc_ward, cex = 0.6, hang = -1)
```

```{r}
sub_grp4 <- cutree(hc_ward, k = 4)
sub_grp5 <- cutree(hc_ward, k = 5)
```

```{r}
numeric <- numeric %>%
  dplyr::mutate(
    group4 = sub_grp4,
    group5 = sub_grp5,
  )
rownames(numeric) <- rownames(scaled_subq)
```

```{r}
#png(here::here("./output/persona/dendogram_4.png"), width = 13, height = 8, units = "in", res = 72)
plot(hc_ward, cex = 0.6)
rect.hclust(hc_ward, k = 4, border = 2:5)
#dev.off()
```

```{r}
#png(here::here("./output/persona/dendogram_5.png"), width = 13, height = 8, units = "in", res = 72)
plot(hc_ward, cex = 0.6)
rect.hclust(hc_ward, k = 5, border = 2:6)
#dev.off()
```

Comparing original dendogram results with subsetted results

```{r}
persona4 <- readr::read_tsv(here("./data/final/persona/persona_group_4.tsv"))

id4 <- persona4 %>%
  dplyr::select(id, group4) %>%
  dplyr::distinct() %>%
  dplyr::arrange(group4) %>%
  dplyr::mutate(id = as.character(id))
```

```{r}
efa4 <- numeric
efa4$id <- rownames(efa4)
efa4 <- efa4[, c("id", "group4")] %>%
  dplyr::arrange(group4) %>%
  #dplyr::mutate(id = as.numeric(id)) %>%
  {.}
```

```{r}
id4
```

```{r}
efa4
```

```{r}
joined_id_group <- dplyr::left_join(id4, efa4, by = "id", suffix = c("_dendo", "_efa")) %>%
  dplyr::mutate(
    group_match = dplyr::if_else(group4_dendo == group4_efa, TRUE, FALSE)
  )
```

```{r}
joined_id_group %>%
  dplyr::group_by(group4_dendo) %>%
  dplyr::summarize(matches = sum(group_match),
                   total = n(),
                   prop_match = round(matches / total, digits = 2)) %>%
  knitr::kable()
```

## CFA Fit

```{r}
fitmeasures(cfa, fit.measures = "all")
```

```{r}
fitmeasures(cfa, c("cfi", "tli", "rmsea", "srmr", "wrmr"))
```

This looks decent, but the rmsea is above 0.05.


